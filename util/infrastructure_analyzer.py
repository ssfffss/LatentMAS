from datetime import datetime
import json
from typing import Dict, List, Optional, Any, Tuple
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from pathlib import Path
from collections import defaultdict
import math
import os
import re
from dataclasses import asdict
import time

def convert_numpy_types(obj):
    """
    é€’å½’åœ°å°†NumPyæ•°æ®ç±»åž‹è½¬æ¢ä¸ºPythonåŽŸç”Ÿç±»åž‹ï¼Œä½¿å…¶å¯JSONåºåˆ—åŒ–
    
    Args:
        obj: ä»»ä½•Pythonå¯¹è±¡
        
    Returns:
        è½¬æ¢åŽçš„å¯¹è±¡ï¼Œæ‰€æœ‰NumPyç±»åž‹éƒ½è¢«è½¬æ¢ä¸ºPythonåŽŸç”Ÿç±»åž‹
    """
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_numpy_types(item) for item in obj)
    elif isinstance(obj, set):
        return {convert_numpy_types(item) for item in obj}
    elif isinstance(obj, datetime):
        return obj.isoformat()
    elif hasattr(obj, '__dict__'):
        # å¤„ç†è‡ªå®šä¹‰å¯¹è±¡
        return convert_numpy_types(obj.__dict__)
    elif obj is None or isinstance(obj, (int, float, str, bool)):
        return obj
    else:
        # å¯¹äºŽå…¶ä»–ç±»åž‹ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        try:
            return str(obj)
        except:
            return "unserializable_object"


class NumpyJSONEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œæ”¯æŒNumPyæ•°æ®ç±»åž‹"""
    
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif isinstance(obj, datetime):
            return obj.isoformat()
        elif hasattr(obj, '__dict__'):
            return obj.__dict__
        return super().default(obj)


class InfrastructureAnalyzer:
    def __init__(self, metrics_dir: str = "metrics", output_dir: str = "analysis_results"):
        self.metrics_dir = Path(metrics_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # åŠ è½½å’Œèšåˆå®žéªŒæ•°æ®
        self.raw_data = self._load_all_metrics()
        self.aggregated_data = self._aggregate_experiments()
        
        print(f"âœ… Loaded {len(self.raw_data)} raw experiments")
        print(f"âœ… Aggregated into {len(self.aggregated_data)} unique experiments")
    
    def _extract_experiment_key(self, experiment_name: str, method: str) -> str:
        return experiment_name
    
    def _load_all_metrics(self) -> Dict[str, List]:
        """åŠ è½½æ‰€æœ‰æŒ‡æ ‡æ•°æ®ï¼ŒåŒ…æ‹¬åŠŸè€—æ•°æ®"""
        all_data = defaultdict(list)
        
        # åŠ è½½ä¸»æŒ‡æ ‡æ–‡ä»¶
        for filepath in self.metrics_dir.glob("*.json"):
            if '_power.json' in str(filepath) or 'report' in str(filepath):
                continue
            filename, _ = os.path.splitext(os.path.basename(filepath))
            
            try:
                with open(filepath) as f:
                    data = json.load(f)
                    method = data.get('method', 'unknown')
                    # experiment_name = data.get('experiment_name', 'unknown')
                    
                    # # ç”Ÿæˆå”¯ä¸€æ ‡è¯†
                    # exp_id = f"{method}_{experiment_name}_{Path(filepath).stem.split('_')[-1]}"
                    # data['file_path'] = str(filepath)
                    # data['experiment_id'] = exp_id

                    power_pattern = f"{filename}_power.json"
                    matching_files = list(self.metrics_dir.glob(power_pattern))
                    if matching_files:
                        power_file = matching_files[0]  # å–ç¬¬ä¸€ä¸ªåŒ¹é…æ–‡ä»¶
                    
                    try:
                        with open(power_file) as f:
                            power_data = json.load(f)
                            data['power_data'] = power_data
                    except Exception as e:
                        print(f"âš ï¸  Error loading power data for {power_pattern}: {e}")

                    all_data[method].append(data)
                    
                    
            except Exception as e:
                print(f"âŒ Error loading {filepath}: {e}")
    
        return all_data
    
    def _aggregate_experiments(self) -> Dict[str, Dict]:
        """èšåˆç›¸åŒå®žéªŒçš„ä¸åŒbatchæ•°æ®"""
        aggregated = {}
        
        # æŒ‰å®žéªŒé”®åˆ†ç»„
        experiment_groups = defaultdict(list)
        
        for method, experiments in self.raw_data.items():
            for exp in experiments:
                exp_key = self._extract_experiment_key(exp['experiment_name'], method)
                experiment_groups[exp_key].append(exp)
        
        print(f"ðŸ“Š Found {len(experiment_groups)} experiment groups: {experiment_groups.keys()} keys to aggregate")
        
        for exp_key, experiments in experiment_groups.items():
            if not experiments:
                continue
            print(f"exp_key: {exp_key}, num_experiments: {len(experiments)}")
            
            # åŸºç¡€å…ƒæ•°æ®ï¼ˆå–ç¬¬ä¸€ä¸ªå®žéªŒçš„ï¼‰
            base_exp = experiments[0]
            method = base_exp['method']
            
            # èšåˆæŒ‡æ ‡
            aggregated_metrics = {
                'compute': [],
                'memory': [],
                'network': [],
                'storage': [],
                'power': []
            }
            
            # èšåˆAgentæŒ‡æ ‡
            aggregated_agents = defaultdict(lambda: defaultdict(list))
            
            total_samples = 0
            total_duration = 0
            total_tokens = 0
            
            for exp in experiments:
                # èšåˆæ•´ä½“æŒ‡æ ‡
                for dimension in ['compute', 'memory', 'network', 'storage', 'power']:
                    if dimension in exp['overall_metrics']:
                        aggregated_metrics[dimension].extend(exp['overall_metrics'][dimension])
                
                # èšåˆAgentæŒ‡æ ‡
                for agent_name, steps in exp['agent_metrics'].items():
                    for step_idx, step_metrics in steps.items():
                        aggregated_agents[agent_name][step_idx].extend(step_metrics)
                
                # ç´¯è®¡ç»Ÿè®¡ä¿¡æ¯
                total_samples += exp['agent_metrics']['Planner']['step_0'][0]['batch_size']  
                total_duration += exp.get('duration', 0)
                
                # ä¼°è®¡tokenæ•°é‡
                if 'compute' in exp['overall_metrics']:
                    for metric in exp['overall_metrics']['compute']:
                        total_tokens += metric.get('tokens_per_second', 0) * metric.get('inference_time', 0)
            
            # è®¡ç®—å¹³å‡å€¼å’Œç»Ÿè®¡ä¿¡æ¯
            summary_stats = {}
            for dimension, metrics in aggregated_metrics.items():
                if metrics:
                    df = pd.DataFrame(metrics)
                    summary_stats[dimension] = {}
                    for col in df.select_dtypes(include=[np.number]).columns:
                        summary_stats[dimension][col] = {
                            'mean': df[col].mean(),
                            'std': df[col].std(),
                            'min': df[col].min(),
                            'max': df[col].max(),
                            'count': len(df)
                        }
            
            # åˆ›å»ºèšåˆåŽçš„å®žéªŒæ•°æ®
            aggregated[exp_key] = {
                'experiment_key': exp_key,
                'method': method,
                'model': base_exp.get('model', 'unknown'),
                'task': exp_key.split('_')[3] if len(exp_key.split('_')) > 3 else 'unknown',
                'batch_count': len(experiments),
                'total_samples': total_samples,
                'total_duration': total_duration,
                'total_tokens': total_tokens,
                'aggregated_metrics': aggregated_metrics,
                'agent_metrics': dict(aggregated_agents),
                'summary_stats': summary_stats,
                'power_summary': self._aggregate_power_data(experiments),
                'experiments': experiments  # ä¿ç•™åŽŸå§‹å®žéªŒæ•°æ®
            }
        
        return aggregated
    
    def _aggregate_power_data(self, experiments: List[Dict]) -> Dict[str, float]:
        """èšåˆå¤šä¸ªå®žéªŒçš„åŠŸè€—æ•°æ®"""
        if not experiments:
            return {}
        
        total_energy = 0.0
        total_duration = 0.0
        peak_power = 0.0
        gpu_energy = 0.0
        cpu_energy = 0.0
        dram_energy = 0.0
        total_tokens = 0
        total_samples = 0
        valid_count = 0
        
        for exp in experiments:
            if 'power_data' in exp and 'power_summary' in exp['power_data']:
                summary = exp['power_data']['power_summary']
                duration = summary.get('measurement_duration', 0)
                
                if duration > 0:
                    total_energy += summary.get('total_energy_consumed', 0)
                    total_duration += duration
                    peak_power = max(peak_power, summary.get('peak_power_draw', 0))
                    
                    # èƒ½é‡å æ¯”
                    energy = summary.get('total_energy_consumed', 0)
                    gpu_energy += energy * summary.get('gpu_energy_fraction', 0)
                    cpu_energy += energy * summary.get('cpu_energy_fraction', 0)
                    dram_energy += energy * summary.get('dram_energy_fraction', 0)
                    
                    # æ€§èƒ½æŒ‡æ ‡
                    total_tokens += summary.get('avg_tokens_per_joule', 0) * energy
                    total_samples += summary.get('avg_samples_per_joule', 0) * energy
                    
                    valid_count += 1
        
        if valid_count == 0 or total_energy == 0:
            return {}
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_power = total_energy / total_duration if total_duration > 0 else 0
        gpu_fraction = gpu_energy / total_energy if total_energy > 0 else 0
        cpu_fraction = cpu_energy / total_energy if total_energy > 0 else 0
        dram_fraction = dram_energy / total_energy if total_energy > 0 else 0
        
        tokens_per_joule = total_tokens / total_energy if total_energy > 0 else 0
        samples_per_joule = total_samples / total_energy if total_energy > 0 else 0
        
        return {
            'total_energy_consumed': total_energy,
            'total_duration': total_duration,
            'avg_power_draw': avg_power,
            'peak_power_draw': peak_power,
            'gpu_energy_fraction': gpu_fraction,
            'cpu_energy_fraction': cpu_fraction,
            'dram_energy_fraction': dram_fraction,
            'avg_tokens_per_joule': tokens_per_joule,
            'avg_samples_per_joule': samples_per_joule,
            'experiment_count': valid_count
        }
    
    def compare_methods(self, methods: List[str] = None):
        """æ¯”è¾ƒä¸åŒæ–¹æ³•çš„æ€§èƒ½ï¼Œç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
        if methods is None:
            methods = list(set(exp['method'] for exp in self.aggregated_data.values()))
        
        print(f"\n{'='*80}")
        print(f"ðŸ“Š INFRASTRUCTURE COMPARISON ANALYSIS")
        print(f"{'='*80}")
        print(f"Methods to compare: {', '.join(methods)}")
        print(f"Total unique experiments: {len(self.aggregated_data)}")
        
        # 1. ç”Ÿæˆè®¡ç®—è´Ÿè½½å¯¹æ¯”
        self._generate_compute_analysis(methods)
        
        # 2. ç”Ÿæˆå†…å­˜è´Ÿè½½å¯¹æ¯”
        self._generate_memory_analysis(methods)
        
        # 3. ç”ŸæˆåŠŸè€—åˆ†æž
        self._generate_power_analysis(methods)
        
        # 4. ç”ŸæˆAgentè¡Œä¸ºåˆ†æž
        self._generate_agent_analysis(methods)
        
        # 5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report(methods)
        
        print(f"\n{'='*80}")
        print(f"âœ… ANALYSIS COMPLETED SUCCESSFULLY")
        print(f"ðŸ“ˆ All charts and reports saved to: {self.output_dir}")
        print(f"{'='*80}")
    
    def _generate_compute_analysis(self, methods):
        """ç”Ÿæˆè®¡ç®—è´Ÿè½½åˆ†æžå›¾è¡¨"""
        print("\nâš¡ Generating compute analysis...")
        
        fig, axes = plt.subplots(2, 2, figsize=(20, 15))
        fig.suptitle('Compute Infrastructure Analysis', fontsize=18, fontweight='bold')
        
        self._plot_inference_time_comparison(methods, axes[0, 0])
        self._plot_gpu_utilization_comparison(methods, axes[0, 1])
        self._plot_tokens_per_second_comparison(methods, axes[1, 0])
        self._plot_flops_efficiency_comparison(methods, axes[1, 1])
        
        plt.tight_layout()
        output_path = self.output_dir / 'compute_infrastructure_analysis.png'
        plt.savefig(output_path, bbox_inches='tight', dpi=300)
        plt.close()
        print(f"âœ… Compute analysis saved to: {output_path}")
    
    def _plot_inference_time_comparison(self, methods, ax):
        """ç»˜åˆ¶æŽ¨ç†æ—¶é—´å¯¹æ¯”"""
        data_by_method = defaultdict(list)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'compute' in exp_data['summary_stats']:
                stats = exp_data['summary_stats']['compute']
                if 'inference_time' in stats:
                    data_by_method[method].append(stats['inference_time']['mean'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No inference time data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        avg_times = [np.mean(data_by_method[method]) for method in method_names]
        std_times = [np.std(data_by_method[method]) for method in method_names]
        
        x = np.arange(len(method_names))
        width = 0.6
        
        bars = ax.bar(x, avg_times, width, yerr=std_times, capsize=5, 
                     color=[self._get_method_color(method) for method in method_names],
                     alpha=0.8, edgecolor='white')
        
        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2, height + 0.05,
                   f'{avg_times[i]:.3f}s\nÂ±{std_times[i]:.3f}', 
                   ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        ax.set_ylabel('Average Inference Time (seconds)', fontweight='bold')
        ax.set_title('Inference Time Comparison', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([f"{method.upper()}\n(n={len(data_by_method[method])})" for method in method_names])
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, max(avg_times) * 1.3 if avg_times else 1)
    
    def _plot_gpu_utilization_comparison(self, methods, ax):
        """ç»˜åˆ¶GPUåˆ©ç”¨çŽ‡å¯¹æ¯”"""
        data_by_method = defaultdict(list)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'compute' in exp_data['summary_stats']:
                stats = exp_data['summary_stats']['compute']
                if 'gpu_util' in stats:
                    data_by_method[method].append(stats['gpu_util']['mean'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No GPU utilization data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        avg_utils = [np.mean(data_by_method[method]) for method in method_names]
        std_utils = [np.std(data_by_method[method]) for method in method_names]
        
        # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
        y = np.arange(len(method_names))
        height = 0.5
        
        bars = ax.barh(y, avg_utils, height, xerr=std_utils, capsize=5,
                      color=[self._get_method_color(method) for method in method_names],
                      alpha=0.8, edgecolor='white')
        
        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax.text(width + 2, bar.get_y() + bar.get_height()/2,
                   f'{avg_utils[i]:.1f}%\nÂ±{std_utils[i]:.1f}', 
                   ha='left', va='center', fontweight='bold', fontsize=9)
        
        ax.set_xlabel('Average GPU Utilization (%)', fontweight='bold')
        ax.set_title('GPU Utilization Comparison', fontsize=14, fontweight='bold')
        ax.set_yticks(y)
        ax.set_yticklabels([f"{method.upper()}\n(n={len(data_by_method[method])})" for method in method_names])
        ax.grid(axis='x', alpha=0.3)
        ax.set_xlim(0, max(avg_utils) * 1.3 if avg_utils else 100)
    
    def _plot_tokens_per_second_comparison(self, methods, ax):
        """ç»˜åˆ¶Tokens/ç§’å¯¹æ¯”"""
        data_by_method = defaultdict(list)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'compute' in exp_data['summary_stats']:
                stats = exp_data['summary_stats']['compute']
                if 'tokens_per_second' in stats:
                    data_by_method[method].append(stats['tokens_per_second']['mean'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No tokens/second data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        avg_tps = [np.mean(data_by_method[method]) for method in method_names]
        std_tps = [np.std(data_by_method[method]) for method in method_names]
        
        x = np.arange(len(method_names))
        width = 0.6
        
        bars = ax.bar(x, avg_tps, width, yerr=std_tps, capsize=5,
                     color=[self._get_method_color(method) for method in method_names],
                     alpha=0.8, edgecolor='white')
        
        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2, height + 10,
                   f'{avg_tps[i]:.0f}\nÂ±{std_tps[i]:.0f}', 
                   ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        ax.set_ylabel('Average Tokens per Second', fontweight='bold')
        ax.set_title('Token Processing Throughput', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([f"{method.upper()}\n(n={len(data_by_method[method])})" for method in method_names])
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, max(avg_tps) * 1.3 if avg_tps else 1000)
    
    def _plot_flops_efficiency_comparison(self, methods, ax):
        """ç»˜åˆ¶FLOPSæ•ˆçŽ‡å¯¹æ¯”"""
        data_by_method = defaultdict(lambda: defaultdict(list))
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            task = exp_data['task']
            if 'compute' in exp_data['summary_stats']:
                stats = exp_data['summary_stats']['compute']
                if 'flops_estimate' in stats:
                    data_by_method[method][task].append(stats['flops_estimate']['mean'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No FLOPS efficiency data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        tasks = sorted(set(task for method_data in data_by_method.values() for task in method_data.keys()))
        
        x = np.arange(len(tasks))
        width = 0.8 / len(method_names)
        
        for i, method in enumerate(method_names):
            avg_flops = []
            for task in tasks:
                values = data_by_method[method].get(task, [])
                avg_flops.append(np.mean(values) if values else 0)
            
            offset = i * width - (len(method_names) - 1) * width / 2
            bars = ax.bar(x + offset, avg_flops, width, 
                         label=method.upper(),
                         color=self._get_method_color(method),
                         alpha=0.8, edgecolor='white')
            
            # æ·»åŠ æ•°æ®æ ‡ç­¾
            for j, bar in enumerate(bars):
                height = bar.get_height()
                if height > 0:
                    ax.text(bar.get_x() + bar.get_width()/2, height + 5,
                           f'{height:.1f}', 
                           ha='center', va='bottom', fontsize=8)
        
        ax.set_ylabel('Average FLOPS (GFLOPS)', fontweight='bold')
        ax.set_title('FLOPS Efficiency by Task', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(tasks, rotation=45, ha='right')
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
        print(f"data_by_method: {data_by_method['latent_mas'].values()} and {data_by_method['text_mas'].values()}")
        ax.set_ylim(0, max(max(flops for flops in data_by_method[method][tasks[0]].values()) for method in method_names) * 1.3 if data_by_method else 1000)
    
    def _generate_memory_analysis(self, methods):
        """ç”Ÿæˆå†…å­˜è´Ÿè½½åˆ†æžå›¾è¡¨"""
        print("\nðŸ“¦ Generating memory analysis...")
        
        fig, axes = plt.subplots(2, 2, figsize=(20, 15))
        fig.suptitle('Memory Infrastructure Analysis', fontsize=18, fontweight='bold')
        
        self._plot_vram_usage_comparison(methods, axes[0, 0])
        self._plot_ram_usage_comparison(methods, axes[0, 1])
        self._plot_kv_cache_comparison(methods, axes[1, 0])
        self._plot_memory_efficiency_comparison(methods, axes[1, 1])
        
        plt.tight_layout()
        output_path = self.output_dir / 'memory_infrastructure_analysis.png'
        plt.savefig(output_path, bbox_inches='tight', dpi=300)
        plt.close()
        print(f"âœ… Memory analysis saved to: {output_path}")
    
    def _plot_vram_usage_comparison(self, methods, ax):
        """ç»˜åˆ¶VRAMä½¿ç”¨å¯¹æ¯”"""
        data_by_method = defaultdict(list)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'memory' in exp_data['summary_stats']:
                stats = exp_data['summary_stats']['memory']
                if 'vram_allocated' in stats:
                    data_by_method[method].append(stats['vram_allocated']['mean'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No VRAM usage data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        avg_vram = [np.mean(data_by_method[method]) for method in method_names]
        std_vram = [np.std(data_by_method[method]) for method in method_names]
        
        x = np.arange(len(method_names))
        width = 0.6
        
        bars = ax.bar(x, avg_vram, width, yerr=std_vram, capsize=5,
                     color=[self._get_method_color(method) for method in method_names],
                     alpha=0.8, edgecolor='white')
        
        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2, height + 0.5,
                   f'{avg_vram[i]:.2f}GB\nÂ±{std_vram[i]:.2f}', 
                   ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        ax.set_ylabel('Average VRAM Usage (GB)', fontweight='bold')
        ax.set_title('VRAM Usage Comparison', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([f"{method.upper()}\n(n={len(data_by_method[method])})" for method in method_names])
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, max(avg_vram) * 1.3 if avg_vram else 24)
    
    def _plot_ram_usage_comparison(self, methods, ax):
        """ç»˜åˆ¶RAMä½¿ç”¨å¯¹æ¯”"""
        data_by_method = defaultdict(list)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'memory' in exp_data['summary_stats']:
                stats = exp_data['summary_stats']['memory']
                if 'ram_used' in stats:
                    data_by_method[method].append(stats['ram_used']['mean'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No RAM usage data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        avg_ram = [np.mean(data_by_method[method]) for method in method_names]
        std_ram = [np.std(data_by_method[method]) for method in method_names]
        
        x = np.arange(len(method_names))
        width = 0.6
        
        bars = ax.bar(x, avg_ram, width, yerr=std_ram, capsize=5,
                     color=[self._get_method_color(method) for method in method_names],
                     alpha=0.8, edgecolor='white')
        
        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2, height + 0.5,
                   f'{avg_ram[i]:.2f}GB\nÂ±{std_ram[i]:.2f}', 
                   ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        ax.set_ylabel('Average RAM Usage (GB)', fontweight='bold')
        ax.set_title('System RAM Usage Comparison', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([f"{method.upper()}\n(n={len(data_by_method[method])})" for method in method_names])
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, max(avg_ram) * 1.3 if avg_ram else 64)
    
    def _plot_kv_cache_comparison(self, methods, ax):
        """ç»˜åˆ¶KVç¼“å­˜å¤§å°å¯¹æ¯”"""
        data_by_method = defaultdict(list)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'memory' in exp_data['summary_stats']:
                stats = exp_data['summary_stats']['memory']
                if 'kv_cache_size' in stats:
                    data_by_method[method].append(stats['kv_cache_size']['mean'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No KV cache data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        avg_kv = [np.mean(data_by_method[method]) for method in method_names]
        std_kv = [np.std(data_by_method[method]) for method in method_names]
        
        x = np.arange(len(method_names))
        width = 0.6
        
        bars = ax.bar(x, avg_kv, width, yerr=std_kv, capsize=5,
                     color=[self._get_method_color(method) for method in method_names],
                     alpha=0.8, edgecolor='white')
        
        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2, height + 0.1,
                   f'{avg_kv[i]:.2f}GB\nÂ±{std_kv[i]:.2f}', 
                   ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        ax.set_ylabel('Average KV Cache Size (GB)', fontweight='bold')
        ax.set_title('KV Cache Size Comparison', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([f"{method.upper()}\n(n={len(data_by_method[method])})" for method in method_names])
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, max(avg_kv) * 1.3 if avg_kv else 10)
    
    def _plot_memory_efficiency_comparison(self, methods, ax):
        """ç»˜åˆ¶å†…å­˜æ•ˆçŽ‡å¯¹æ¯”ï¼ˆVRAM + RAMï¼‰"""
        data_by_method = defaultdict(lambda: {'vram': [], 'ram': []})
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'memory' in exp_data['summary_stats']:
                stats = exp_data['summary_stats']['memory']
                if 'vram_allocated' in stats:
                    data_by_method[method]['vram'].append(stats['vram_allocated']['mean'])
                if 'ram_used' in stats:
                    data_by_method[method]['ram'].append(stats['ram_used']['mean'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No memory efficiency data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        x = np.arange(len(method_names))
        width = 0.4
        
        # VRAMéƒ¨åˆ†
        vram_means = [np.mean(data_by_method[method]['vram']) for method in method_names]
        ax.bar(x - width/2, vram_means, width, label='VRAM Usage',
               color=[self._get_method_color(method) for method in method_names],
               alpha=0.8, edgecolor='white')
        
        # RAMéƒ¨åˆ†
        ram_means = [np.mean(data_by_method[method]['ram']) for method in method_names]
        ax.bar(x + width/2, ram_means, width, label='RAM Usage',
               color=[self._get_method_color(method) for method in method_names],
               alpha=0.8, hatch='//', edgecolor='white')
        
        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for i, (vram, ram) in enumerate(zip(vram_means, ram_means)):
            ax.text(x[i] - width/2, vram + 0.5, f'{vram:.2f}GB', 
                   ha='center', va='bottom', fontsize=8, rotation=45)
            ax.text(x[i] + width/2, ram + 0.5, f'{ram:.2f}GB', 
                   ha='center', va='bottom', fontsize=8, rotation=45)
        
        ax.set_ylabel('Memory Usage (GB)', fontweight='bold')
        ax.set_title('Memory Efficiency: VRAM vs RAM', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([method.upper() for method in method_names])
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
        max_val = max(max(vram_means), max(ram_means)) if vram_means and ram_means else 10
        ax.set_ylim(0, max_val * 1.3)
    
    def _generate_power_analysis(self, methods):
        """ç”ŸæˆåŠŸè€—åˆ†æžå›¾è¡¨"""
        print("\nâš¡ Generating power analysis...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŠŸè€—æ•°æ®
        has_power_data = any('power_summary' in exp_data and exp_data['power_summary'] 
                           for exp_data in self.aggregated_data.values())
        
        if not has_power_data:
            print("âš ï¸  No power data available for analysis")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(20, 15))
        fig.suptitle('Power Consumption Analysis', fontsize=18, fontweight='bold')
        
        self._plot_energy_consumption(methods, axes[0, 0])
        self._plot_power_efficiency(methods, axes[0, 1])
        self._plot_energy_breakdown(methods, axes[1, 0])
        self._plot_cost_analysis(methods, axes[1, 1])
        
        plt.tight_layout()
        output_path = self.output_dir / 'power_consumption_analysis.png'
        plt.savefig(output_path, bbox_inches='tight', dpi=300)
        plt.close()
        print(f"âœ… Power analysis saved to: {output_path}")
    
    def _plot_energy_consumption(self, methods, ax):
        """ç»˜åˆ¶èƒ½è€—å¯¹æ¯”"""
        data_by_method = defaultdict(list)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'power_summary' in exp_data and exp_data['power_summary']:
                summary = exp_data['power_summary']
                data_by_method[method].append(summary['total_energy_consumed'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No energy consumption data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        avg_energy = [np.mean(data_by_method[method]) for method in method_names]
        std_energy = [np.std(data_by_method[method]) for method in method_names]
        
        x = np.arange(len(method_names))
        width = 0.6
        
        bars = ax.bar(x, avg_energy, width, yerr=std_energy, capsize=5,
                     color=[self._get_method_color(method) for method in method_names],
                     alpha=0.8, edgecolor='white')
        
        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2, height + 1,
                   f'{avg_energy[i]:.2f}J\nÂ±{std_energy[i]:.2f}', 
                   ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        ax.set_ylabel('Total Energy Consumed (Joules)', fontweight='bold')
        ax.set_title('Energy Consumption per Experiment', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([f"{method.upper()}\n(n={len(data_by_method[method])})" for method in method_names])
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, max(avg_energy) * 1.3 if avg_energy else 100)
    
    def _plot_power_efficiency(self, methods, ax):
        """ç»˜åˆ¶èƒ½æ•ˆå¯¹æ¯”ï¼ˆTokens/Jouleï¼‰"""
        data_by_method = defaultdict(list)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'power_summary' in exp_data and exp_data['power_summary']:
                summary = exp_data['power_summary']
                if 'avg_tokens_per_joule' in summary:
                    data_by_method[method].append(summary['avg_tokens_per_joule'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No power efficiency data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        avg_efficiency = [np.mean(data_by_method[method]) for method in method_names]
        std_efficiency = [np.std(data_by_method[method]) for method in method_names]
        
        x = np.arange(len(method_names))
        width = 0.6
        
        bars = ax.bar(x, avg_efficiency, width, yerr=std_efficiency, capsize=5,
                     color=[self._get_method_color(method) for method in method_names],
                     alpha=0.8, edgecolor='white')
        
        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2, height + 5,
                   f'{avg_efficiency[i]:.1f}\nÂ±{std_efficiency[i]:.1f}', 
                   ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        ax.set_ylabel('Tokens per Joule', fontweight='bold')
        ax.set_title('Energy Efficiency: Tokens per Joule', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([f"{method.upper()}\n(n={len(data_by_method[method])})" for method in method_names])
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, max(avg_efficiency) * 1.3 if avg_efficiency else 100)
    
    def _plot_energy_breakdown(self, methods, ax):
        """ç»˜åˆ¶èƒ½è€—åˆ†è§£ï¼ˆGPU/CPU/DRAMï¼‰"""
        data_by_method = defaultdict(lambda: {'gpu': [], 'cpu': [], 'dram': []})
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'power_summary' in exp_data and exp_data['power_summary']:
                summary = exp_data['power_summary']
                data_by_method[method]['gpu'].append(summary['gpu_energy_fraction'])
                data_by_method[method]['cpu'].append(summary['cpu_energy_fraction'])
                data_by_method[method]['dram'].append(summary['dram_energy_fraction'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No energy breakdown data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        x = np.arange(len(method_names))
        width = 0.6
        
        # GPUéƒ¨åˆ†
        gpu_means = [np.mean(data_by_method[method]['gpu']) for method in method_names]
        bottom = np.zeros(len(method_names))
        
        gpu_bars = ax.bar(x, gpu_means, width, bottom=bottom, 
                         label='GPU Energy', color='#FF6B6B', alpha=0.8)
        bottom += gpu_means
        
        # CPUéƒ¨åˆ†
        cpu_means = [np.mean(data_by_method[method]['cpu']) for method in method_names]
        cpu_bars = ax.bar(x, cpu_means, width, bottom=bottom, 
                         label='CPU Energy', color='#4ECDC4', alpha=0.8)
        bottom += cpu_means
        
        # DRAMéƒ¨åˆ†
        dram_means = [np.mean(data_by_method[method]['dram']) for method in method_names]
        dram_bars = ax.bar(x, dram_means, width, bottom=bottom, 
                          label='DRAM Energy', color='#45B7D1', alpha=0.8)
        
        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for i, (gpu, cpu, dram) in enumerate(zip(gpu_means, cpu_means, dram_means)):
            total = gpu + cpu + dram
            if gpu > 0.1:
                ax.text(x[i], gpu/2, f'GPU: {gpu:.1%}', 
                       ha='center', va='center', color='white', fontweight='bold', fontsize=8)
            if cpu > 0.1:
                ax.text(x[i], gpu + cpu/2, f'CPU: {cpu:.1%}', 
                       ha='center', va='center', color='white', fontweight='bold', fontsize=8)
            if dram > 0.1:
                ax.text(x[i], gpu + cpu + dram/2, f'DRAM: {dram:.1%}', 
                       ha='center', va='center', color='white', fontweight='bold', fontsize=8)
        
        ax.set_ylabel('Energy Fraction', fontweight='bold')
        ax.set_title('Energy Consumption Breakdown', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([method.upper() for method in method_names])
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, 1.1)
    
    def _plot_cost_analysis(self, methods, ax):
        """ç»˜åˆ¶æˆæœ¬åˆ†æž"""
        data_by_method = defaultdict(list)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'power_summary' in exp_data and exp_data['power_summary']:
                summary = exp_data['power_summary']
                data_by_method[method].append(summary['total_energy_consumed'])
        
        if not data_by_method:
            ax.text(0.5, 0.5, 'No cost analysis data available', ha='center', va='center')
            return
        
        # ä¼°ç®—æˆæœ¬ï¼ˆåŸºäºŽç¾Žå›½å¹³å‡ç”µä»· $0.12/kWhï¼‰
        electricity_cost_per_kwh = 0.12
        samples_per_day = 1000000  # 1Mæ ·æœ¬/å¤©
        days_per_year = 365
        
        # å‡†å¤‡æ•°æ®
        method_names = list(data_by_method.keys())
        costs_per_year = []
        
        for method in method_names:
            avg_energy_per_sample = np.mean(data_by_method[method]) / samples_per_day
            yearly_energy_kwh = (avg_energy_per_sample * samples_per_day * days_per_year) / 3600000
            yearly_cost = yearly_energy_kwh * electricity_cost_per_kwh
            costs_per_year.append(yearly_cost)
        
        x = np.arange(len(method_names))
        width = 0.6
        
        bars = ax.bar(x, costs_per_year, width,
                     color=[self._get_method_color(method) for method in method_names],
                     alpha=0.8, edgecolor='white')
        
        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2, height + 100,
                   f'${height:,.0f}', 
                   ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        ax.set_ylabel('Estimated Annual Cost ($)', fontweight='bold')
        ax.set_title(f'Cost Analysis at Scale\n({samples_per_day/1000000:.1f}M samples/day, ${electricity_cost_per_kwh:.2f}/kWh)', 
                    fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([method.upper() for method in method_names])
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, max(costs_per_year) * 1.3 if costs_per_year else 10000)
    
    def _generate_agent_analysis(self, methods):
        """ç”ŸæˆAgentè¡Œä¸ºåˆ†æžå›¾è¡¨"""
        print("\nðŸ¤– Generating agent analysis...")
        
        fig, axes = plt.subplots(2, 2, figsize=(20, 15))
        fig.suptitle('Multi-Agent Behavior Analysis', fontsize=18, fontweight='bold')
        
        self._plot_agent_computation_breakdown(methods, axes[0, 0])
        self._plot_agent_memory_usage(methods, axes[0, 1])
        self._plot_agent_power_consumption(methods, axes[1, 0])
        self._plot_agent_efficiency(methods, axes[1, 1])
        
        plt.tight_layout()
        output_path = self.output_dir / 'agent_behavior_analysis.png'
        plt.savefig(output_path, bbox_inches='tight', dpi=300)
        plt.close()
        print(f"âœ… Agent analysis saved to: {output_path}")
    
    def _plot_agent_computation_breakdown(self, methods, ax):
        """ç»˜åˆ¶Agentè®¡ç®—æ—¶é—´åˆ†è§£"""
        agent_data = defaultdict(lambda: defaultdict(lambda: {'cpu': [], 'gpu': []}))
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            # ä»ŽAgentæŒ‡æ ‡ä¸­æå–æ•°æ®
            for agent_name, steps in exp_data['agent_metrics'].items():
                for step_idx, metrics in steps.items():
                    for metric in metrics:
                        compute = metric.get('compute', {})
                        inference_time = compute.get('inference_time', 0)
                        total_time = compute.get('total_time', inference_time + 0.1)
                        
                        cpu_time = total_time - inference_time
                        gpu_time = inference_time
                        
                        cpu_ratio = cpu_time / total_time if total_time > 0 else 0
                        gpu_ratio = gpu_time / total_time if total_time > 0 else 0
                        
                        agent_data[method][agent_name]['cpu'].append(cpu_ratio)
                        agent_data[method][agent_name]['gpu'].append(gpu_ratio)
        
        if not agent_data:
            ax.text(0.5, 0.5, 'No agent computation data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(agent_data.keys())
        agent_names = sorted(set(agent for method_data in agent_data.values() 
                               for agent in method_data.keys()))
        
        x = np.arange(len(agent_names))
        width = 0.8 / len(method_names)
        
        for i, method in enumerate(method_names):
            cpu_ratios = []
            gpu_ratios = []
            
            for agent in agent_names:
                if agent in agent_data[method]:
                    cpu_vals = agent_data[method][agent]['cpu']
                    gpu_vals = agent_data[method][agent]['gpu']
                    cpu_ratios.append(np.mean(cpu_vals) if cpu_vals else 0)
                    gpu_ratios.append(np.mean(gpu_vals) if gpu_vals else 0)
                else:
                    cpu_ratios.append(0)
                    gpu_ratios.append(0)
            
            offset = i * width - (len(method_names) - 1) * width / 2
            bottom = np.zeros(len(agent_names))
            
            # CPUéƒ¨åˆ†
            cpu_bars = ax.bar(x + offset, cpu_ratios, width, bottom=bottom,
                            label=f'{method.upper()} CPU',
                            color=self._get_method_color(method),
                            alpha=0.3, edgecolor='white')
            bottom += cpu_ratios
            
            # GPUéƒ¨åˆ†
            gpu_bars = ax.bar(x + offset, gpu_ratios, width, bottom=bottom,
                            label=f'{method.upper()} GPU',
                            color=self._get_method_color(method),
                            alpha=0.8, edgecolor='white')
            
            # æ·»åŠ æ•°æ®æ ‡ç­¾
            for j, (cpu, gpu) in enumerate(zip(cpu_ratios, gpu_ratios)):
                total = cpu + gpu
                if total > 0.1:  # åªæ˜¾ç¤ºæ˜¾è‘—çš„å€¼
                    cpu_pct = cpu / total * 100
                    gpu_pct = gpu / total * 100
                    
                    if cpu_pct > 15:
                        ax.text(x[j] + offset, bottom[j] - gpu/2, f'CPU:{cpu_pct:.0f}%', 
                               ha='center', va='center', fontsize=6, color='black')
                    if gpu_pct > 15:
                        ax.text(x[j] + offset, bottom[j] - gpu/2, f'GPU:{gpu_pct:.0f}%', 
                               ha='center', va='center', fontsize=6, color='white')
        
        ax.set_ylabel('Time Ratio', fontweight='bold')
        ax.set_title('Agent Computation Time Breakdown', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(agent_names, rotation=45, ha='right')
        ax.legend(loc='upper right', bbox_to_anchor=(1.15, 1.0))
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, 1.1)
    
    def _plot_agent_memory_usage(self, methods, ax):
        """ç»˜åˆ¶Agentå†…å­˜ä½¿ç”¨æƒ…å†µ"""
        agent_data = defaultdict(lambda: defaultdict(lambda: {'vram': [], 'ram': []}))
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            for agent_name, steps in exp_data['agent_metrics'].items():
                for step_idx, metrics in steps.items():
                    for metric in metrics:
                        memory = metric.get('memory', {})
                        vram = memory.get('vram_allocated', 0)
                        ram = memory.get('ram_used', 0)
                        
                        agent_data[method][agent_name]['vram'].append(vram)
                        agent_data[method][agent_name]['ram'].append(ram)
        
        if not agent_data:
            ax.text(0.5, 0.5, 'No agent memory data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(agent_data.keys())
        agent_names = sorted(set(agent for method_data in agent_data.values() 
                               for agent in method_data.keys()))
        
        x = np.arange(len(agent_names))
        width = 0.8 / len(method_names)
        
        max_value = 0
        
        for i, method in enumerate(method_names):
            vram_means = []
            ram_means = []
            
            for agent in agent_names:
                if agent in agent_data[method]:
                    vram_vals = agent_data[method][agent]['vram']
                    ram_vals = agent_data[method][agent]['ram']
                    vram_means.append(np.mean(vram_vals) if vram_vals else 0)
                    ram_means.append(np.mean(ram_vals) if ram_vals else 0)
                else:
                    vram_means.append(0)
                    ram_means.append(0)
            
            max_value = max(max_value, max(vram_means), max(ram_means))
            
            offset = i * width - (len(method_names) - 1) * width / 2
            
            # VRAMéƒ¨åˆ†
            vram_bars = ax.bar(x + offset, vram_means, width,
                             label=f'{method.upper()} VRAM',
                             color=self._get_method_color(method),
                             alpha=0.8, edgecolor='white')
            
            # RAMéƒ¨åˆ† (å †å åœ¨VRAMä¸Šæ–¹)
            ram_bars = ax.bar(x + offset, ram_means, width, bottom=vram_means,
                            label=f'{method.upper()} RAM',
                            color=self._get_method_color(method),
                            alpha=0.8, hatch='//', edgecolor='white')
            
            # æ·»åŠ æ•°æ®æ ‡ç­¾
            for j, (vram, ram) in enumerate(zip(vram_means, ram_means)):
                if vram > 0.5:
                    ax.text(x[j] + offset, vram/2, f'{vram:.1f}GB', 
                           ha='center', va='center', fontsize=6, color='white')
                if ram > 0.5:
                    ax.text(x[j] + offset, vram + ram/2, f'{ram:.1f}GB', 
                           ha='center', va='center', fontsize=6, color='black')
        
        ax.set_ylabel('Memory Usage (GB)', fontweight='bold')
        ax.set_title('Agent Memory Usage Comparison', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(agent_names, rotation=45, ha='right')
        ax.legend(loc='upper right', bbox_to_anchor=(1.15, 1.0))
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim(0, max_value * 1.3 if max_value > 0 else 24)
    
    def _plot_agent_power_consumption(self, methods, ax):
        """ç»˜åˆ¶AgentåŠŸè€—åˆ†æž"""
        agent_data = defaultdict(lambda: defaultdict(list))
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'power_summary' in exp_data and exp_data['power_summary']:
                # è¿™é‡Œéœ€è¦æ›´ç»†ç²’åº¦çš„AgentåŠŸè€—æ•°æ®
                # ä¸´æ—¶ä½¿ç”¨æ•´ä½“åŠŸè€—æ•°æ®ä½œä¸ºæ›¿ä»£
                total_energy = exp_data['power_summary']['total_energy_consumed']
                agent_count = len(exp_data['agent_metrics'])
                
                for agent_name in exp_data['agent_metrics'].keys():
                    agent_data[method][agent_name].append(total_energy / agent_count if agent_count > 0 else 0)
        
        if not agent_data:
            ax.text(0.5, 0.5, 'No agent power data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(agent_data.keys())
        agent_names = sorted(set(agent for method_data in agent_data.values() 
                               for agent in method_data.keys()))
        
        x = np.arange(len(agent_names))
        width = 0.8 / len(method_names)
        
        for i, method in enumerate(method_names):
            energy_means = []
            
            for agent in agent_names:
                if agent in agent_data[method]:
                    energy_means.append(np.mean(agent_data[method][agent]))
                else:
                    energy_means.append(0)
            
            offset = i * width - (len(method_names) - 1) * width / 2
            bars = ax.bar(x + offset, energy_means, width,
                        label=method.upper(),
                        color=self._get_method_color(method),
                        alpha=0.8, edgecolor='white')
            
            # æ·»åŠ æ•°æ®æ ‡ç­¾
            for j, bar in enumerate(bars):
                height = bar.get_height()
                if height > 1:  # åªæ˜¾ç¤ºæ˜¾è‘—çš„å€¼
                    ax.text(bar.get_x() + bar.get_width()/2, height + 0.5,
                           f'{height:.1f}J', 
                           ha='center', va='bottom', fontsize=8)
        
        ax.set_ylabel('Energy per Agent (Joules)', fontweight='bold')
        ax.set_title('Agent Power Consumption Comparison', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(agent_names, rotation=45, ha='right')
        ax.legend(loc='upper right', bbox_to_anchor=(1.15, 1.0))
        ax.grid(axis='y', alpha=0.3)
        max_val = max(max(energy_means) for energy_means in agent_data.values()) if agent_data else 100
        ax.set_ylim(0, max_val * 1.3)
    
    def _plot_agent_efficiency(self, methods, ax):
        """ç»˜åˆ¶Agentæ•ˆçŽ‡åˆ†æžï¼ˆTokens/Jouleï¼‰"""
        agent_data = defaultdict(lambda: defaultdict(list))
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'power_summary' in exp_data and exp_data['power_summary']:
                tokens_per_joule = exp_data['power_summary'].get('avg_tokens_per_joule', 0)
                for agent_name in exp_data['agent_metrics'].keys():
                    agent_data[method][agent_name].append(tokens_per_joule)
        
        if not agent_data:
            ax.text(0.5, 0.5, 'No agent efficiency data available', ha='center', va='center')
            return
        
        # å‡†å¤‡æ•°æ®
        method_names = list(agent_data.keys())
        agent_names = sorted(set(agent for method_data in agent_data.values() 
                               for agent in method_data.keys()))
        
        x = np.arange(len(agent_names))
        width = 0.8 / len(method_names)
        
        for i, method in enumerate(method_names):
            efficiency_means = []
            
            for agent in agent_names:
                if agent in agent_data[method]:
                    efficiency_means.append(np.mean(agent_data[method][agent]))
                else:
                    efficiency_means.append(0)
            
            offset = i * width - (len(method_names) - 1) * width / 2
            bars = ax.bar(x + offset, efficiency_means, width,
                        label=method.upper(),
                        color=self._get_method_color(method),
                        alpha=0.8, edgecolor='white')
            
            # æ·»åŠ æ•°æ®æ ‡ç­¾
            for j, bar in enumerate(bars):
                height = bar.get_height()
                if height > 10:  # åªæ˜¾ç¤ºæ˜¾è‘—çš„å€¼
                    ax.text(bar.get_x() + bar.get_width()/2, height + 5,
                           f'{height:.0f}', 
                           ha='center', va='bottom', fontsize=8)
        
        ax.set_ylabel('Tokens per Joule', fontweight='bold')
        ax.set_title('Agent Energy Efficiency', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(agent_names, rotation=45, ha='right')
        ax.legend(loc='upper right', bbox_to_anchor=(1.15, 1.0))
        ax.grid(axis='y', alpha=0.3)
        max_val = max(max(efficiency_means) for efficiency_means in agent_data.values()) if agent_data else 100
        ax.set_ylim(0, max_val * 1.3)
    
    def _get_method_color(self, method: str) -> str:
        """èŽ·å–æ–¹æ³•å¯¹åº”çš„é¢œè‰²"""
        color_map = {
            'latent_mas': '#4ECDC4',  # é’è‰² - è¡¨ç¤ºä¼˜åŒ–
            'text_mas': '#FF6B6B',    # çº¢è‰² - è¡¨ç¤ºåŸºçº¿
            'baseline': '#45B7D1',    # è“è‰² - è¡¨ç¤ºå•Agent
            'cpu': '#96CEB4',         # ç»¿è‰²
            'gpu': '#FECA57',         # æ©™è‰²
            'ram': '#A78BFA',         # ç´«è‰²
            'vram': '#F08080',        # ç²‰è‰²
        }
        return color_map.get(method.lower(), '#95A5A6')
    
    def generate_comprehensive_report(self, methods: List[str]):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        report = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'analysis_version': '1.0',
                'metrics_dir': str(self.metrics_dir),
                'total_experiments': len(self.aggregated_data),
                'methods_analyzed': methods
            },
            'summary': {},
            'method_comparisons': {},
            'recommendations': [],
            'insights': {}
        }
        
        # 1. è®¡ç®—å…³é”®æŒ‡æ ‡
        method_stats = defaultdict(dict)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            # åŸºç¡€ç»Ÿè®¡
            inference_time = exp_data['summary_stats']['compute']['inference_time']['mean'] if 'compute' in exp_data['summary_stats'] and 'inference_time' in exp_data['summary_stats']['compute'] else 0
            vram_usage = exp_data['summary_stats']['memory']['vram_allocated']['mean'] if 'memory' in exp_data['summary_stats'] and 'vram_allocated' in exp_data['summary_stats']['memory'] else 0
            tokens_per_second = exp_data['summary_stats']['compute']['tokens_per_second']['mean'] if 'compute' in exp_data['summary_stats'] and 'tokens_per_second' in exp_data['summary_stats']['compute'] else 0
            
            # åŠŸè€—ç»Ÿè®¡
            energy_efficiency = 0
            cost_per_million = 0
            
            if 'power_summary' in exp_data and exp_data['power_summary']:
                power_summary = exp_data['power_summary']
                energy_efficiency = power_summary.get('avg_tokens_per_joule', 0)
                
                # ä¼°ç®—æˆæœ¬
                electricity_cost_per_kwh = 0.12
                samples_per_day = 1000000
                energy_per_sample = power_summary.get('total_energy_consumed', 0) / exp_data['total_samples'] if exp_data['total_samples'] > 0 else 0
                daily_energy_kwh = (energy_per_sample * samples_per_day) / 3600000
                daily_cost = daily_energy_kwh * electricity_cost_per_kwh
                cost_per_million = daily_cost
            
            method_stats[method][exp_key] = {
                'inference_time': inference_time,
                'vram_usage': vram_usage,
                'tokens_per_second': tokens_per_second,
                'energy_efficiency': energy_efficiency,
                'cost_per_million': cost_per_million
            }
        
        # 2. ç”Ÿæˆæ–¹æ³•å¯¹æ¯”
        if method_stats:
            report['method_comparisons'] = convert_numpy_types(method_stats)
            
            # 3. ç”Ÿæˆå»ºè®®
            if 'latent_mas' in method_stats and ('text_mas' in method_stats or 'baseline' in method_stats):
                latent_stats = method_stats['latent_mas']
                comparison_method = 'text_mas' if 'text_mas' in method_stats else 'baseline'
                comparison_stats = method_stats[comparison_method]
                
                # æ€§èƒ½å¯¹æ¯”
                latent_inference = np.mean([stats['inference_time'] for stats in latent_stats.values()])
                comparison_inference = np.mean([stats['inference_time'] for stats in comparison_stats.values()])
                
                # VRAMå¯¹æ¯”
                latent_vram = np.mean([stats['vram_usage'] for stats in latent_stats.values()])
                comparison_vram = np.mean([stats['vram_usage'] for stats in comparison_stats.values()])
                
                # èƒ½æ•ˆå¯¹æ¯”
                latent_efficiency = np.mean([stats['energy_efficiency'] for stats in latent_stats.values()])
                comparison_efficiency = np.mean([stats['energy_efficiency'] for stats in comparison_stats.values()])
                
                # ç”Ÿæˆå…·ä½“å»ºè®®
                if latent_inference < comparison_inference * 0.7:
                    savings_pct = (1 - latent_inference / comparison_inference) * 100
                    report['recommendations'].append(
                        f"LatentMAS reduces inference time by {savings_pct:.1f}%, "
                        f"making it ideal for latency-sensitive applications."
                    )
                
                if latent_vram < comparison_vram * 0.85:
                    savings_pct = (1 - latent_vram / comparison_vram) * 100
                    report['recommendations'].append(
                        f"LatentMAS reduces VRAM usage by {savings_pct:.1f}%, "
                        f"enabling deployment on lower-memory GPUs."
                    )
                
                if latent_efficiency > comparison_efficiency * 1.5:
                    improvement_pct = (latent_efficiency / comparison_efficiency - 1) * 100
                    report['recommendations'].append(
                        f"LatentMAS improves energy efficiency by {improvement_pct:.1f}%, "
                        f"providing significant cost savings at scale."
                    )
        
        # 4. ç”Ÿæˆå…³é”®æ´žå¯Ÿ
        report['insights'] = {
            'compute_insights': self._generate_compute_insights(methods),
            'memory_insights': self._generate_memory_insights(methods),
            'power_insights': self._generate_power_insights(methods),
            'agent_insights': self._generate_agent_insights(methods)
        }
        
        # 5. ä¿å­˜æŠ¥å‘Š
        report_path = self.output_dir / 'infrastructure_analysis_report.json'
        with open(report_path, 'w') as f:
            json.dump(convert_numpy_types(report), f, indent=2, cls=NumpyJSONEncoder)
        
        print(f"\n{'='*80}")
        print("ðŸ“‹ COMPREHENSIVE ANALYSIS REPORT")
        print(f"{'='*80}")
        print(f"Report saved to: {report_path}")
        print(f"\nðŸ“Š KEY INSIGHTS:")
        
        for category, insights in report['insights'].items():
            print(f"\n{category.replace('_', ' ').title()}:")
            for insight in insights:
                print(f"â€¢ {insight}")
        
        if report['recommendations']:
            print(f"\nðŸ’¡ KEY RECOMMENDATIONS:")
            for i, rec in enumerate(report['recommendations'], 1):
                print(f"{i}. {rec}")
        
        print(f"{'='*80}")
        
        return report
    
    def _generate_compute_insights(self, methods) -> List[str]:
        """ç”Ÿæˆè®¡ç®—ç›¸å…³çš„æ´žå¯Ÿ"""
        insights = []
        
        # åˆ†æžæŽ¨ç†æ—¶é—´
        inference_times = defaultdict(list)
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            if 'compute' in exp_data['summary_stats'] and 'inference_time' in exp_data['summary_stats']['compute']:
                inference_times[method].append(exp_data['summary_stats']['compute']['inference_time']['mean'])
        
        if inference_times:
            fastest_method = min(inference_times.items(), key=lambda x: np.mean(x[1]) if x[1] else float('inf'))[0]
            slowest_method = max(inference_times.items(), key=lambda x: np.mean(x[1]) if x[1] else 0)[0]
            
            if fastest_method != slowest_method:
                insights.append(
                    f"{fastest_method.upper()} achieves {np.mean(inference_times[slowest_method])/np.mean(inference_times[fastest_method]):.1f}x "
                    f"faster inference compared to {slowest_method.upper()}"
                )
        
        return insights
    
    def _generate_memory_insights(self, methods) -> List[str]:
        """ç”Ÿæˆå†…å­˜ç›¸å…³çš„æ´žå¯Ÿ"""
        insights = []
        
        vram_usage = defaultdict(list)
        kv_cache_size = defaultdict(list)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'memory' in exp_data['summary_stats']:
                stats = exp_data['summary_stats']['memory']
                if 'vram_allocated' in stats:
                    vram_usage[method].append(stats['vram_allocated']['mean'])
                if 'kv_cache_size' in stats:
                    kv_cache_size[method].append(stats['kv_cache_size']['mean'])
        
        if vram_usage:
            most_efficient = min(vram_usage.items(), key=lambda x: np.mean(x[1]) if x[1] else float('inf'))[0]
            least_efficient = max(vram_usage.items(), key=lambda x: np.mean(x[1]) if x[1] else 0)[0]
            
            if most_efficient != least_efficient:
                insights.append(
                    f"{most_efficient.upper()} uses {np.mean(vram_usage[least_efficient])/np.mean(vram_usage[most_efficient]):.1f}x "
                    f"less VRAM compared to {least_efficient.upper()}"
                )
        
        if kv_cache_size:
            smallest_kv = min(kv_cache_size.items(), key=lambda x: np.mean(x[1]) if x[1] else float('inf'))[0]
            largest_kv = max(kv_cache_size.items(), key=lambda x: np.mean(x[1]) if x[1] else 0)[0]
            
            if smallest_kv != largest_kv:
                insights.append(
                    f"{smallest_kv.upper()} reduces KV cache size by {1 - np.mean(kv_cache_size[smallest_kv])/np.mean(kv_cache_size[largest_kv]):.1%}, "
                    f"significantly improving memory efficiency"
                )
        
        return insights
    
    def _generate_power_insights(self, methods) -> List[str]:
        """ç”ŸæˆåŠŸè€—ç›¸å…³çš„æ´žå¯Ÿ"""
        insights = []
        
        energy_efficiency = defaultdict(list)
        total_energy = defaultdict(list)
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            if 'power_summary' in exp_data and exp_data['power_summary']:
                summary = exp_data['power_summary']
                energy_efficiency[method].append(summary.get('avg_tokens_per_joule', 0))
                total_energy[method].append(summary.get('total_energy_consumed', 0))
        
        if energy_efficiency:
            most_efficient = max(energy_efficiency.items(), key=lambda x: np.mean(x[1]) if x[1] else 0)[0]
            least_efficient = min(energy_efficiency.items(), key=lambda x: np.mean(x[1]) if x[1] else float('inf'))[0]
            
            if most_efficient != least_efficient:
                insights.append(
                    f"{most_efficient.upper()} achieves {np.mean(energy_efficiency[most_efficient])/np.mean(energy_efficiency[least_efficient]):.1f}x "
                    f"better energy efficiency (tokens/joule) than {least_efficient.upper()}"
                )
        
        if total_energy:
            lowest_energy = min(total_energy.items(), key=lambda x: np.mean(x[1]) if x[1] else float('inf'))[0]
            highest_energy = max(total_energy.items(), key=lambda x: np.mean(x[1]) if x[1] else 0)[0]
            
            if lowest_energy != highest_energy:
                insights.append(
                    f"{lowest_energy.upper()} consumes {np.mean(total_energy[highest_energy])/np.mean(total_energy[lowest_energy]):.1f}x "
                    f"less total energy than {highest_energy.upper()}, reducing operational costs"
                )
        
        return insights
    
    def _generate_agent_insights(self, methods) -> List[str]:
        """ç”ŸæˆAgentç›¸å…³çš„æ´žå¯Ÿ"""
        insights = []
        
        # åˆ†æžAgentè®¡ç®—æ¨¡å¼
        cpu_gpu_ratios = defaultdict(lambda: defaultdict(list))
        
        for exp_key, exp_data in self.aggregated_data.items():
            method = exp_data['method']
            if method not in methods:
                continue
            
            for agent_name, steps in exp_data['agent_metrics'].items():
                for step_idx, metrics in steps.items():
                    for metric in metrics:
                        compute = metric.get('compute', {})
                        inference_time = compute.get('inference_time', 0)
                        total_time = compute.get('total_time', inference_time + 0.1)
                        
                        gpu_ratio = inference_time / total_time if total_time > 0 else 0
                        cpu_ratio = 1 - gpu_ratio
                        
                        cpu_gpu_ratios[method][agent_name].append((cpu_ratio, gpu_ratio))
        
        if cpu_gpu_ratios:
            for method, agent_data in cpu_gpu_ratios.items():
                for agent_name, ratios in agent_data.items():
                    avg_cpu = np.mean([r[0] for r in ratios])
                    avg_gpu = np.mean([r[1] for r in ratios])
                    
                    if avg_gpu > 0.7:
                        insights.append(
                            f"{agent_name} in {method.upper()} is GPU-bound ({avg_gpu:.1%} GPU time), "
                            f"suggesting optimization opportunities for GPU utilization"
                        )
                    elif avg_cpu > 0.7:
                        insights.append(
                            f"{agent_name} in {method.upper()} is CPU-bound ({avg_cpu:.1%} CPU time), "
                            f"indicating potential bottlenecks in data preprocessing or memory management"
                        )
        
        return insights
    
    def generate_visualization_code(self):
        """ç”Ÿæˆå¯è§†åŒ–ä»£ç ç¤ºä¾‹"""
        viz_code = f"""
# Infrastructure Analysis Visualization Code
# Generated on {datetime.now().isoformat()}

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from pathlib import Path

# Set style
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# Load analysis data
analysis_dir = Path('{self.output_dir}')
report_path = analysis_dir / 'infrastructure_analysis_report.json'

with open(report_path) as f:
    report = json.load(f)

# Example: Plot inference time comparison
methods = {list(set(exp['method'] for exp in self.aggregated_data.values()))}
inference_times = {{}}

for exp_key, exp_data in {dict(self.aggregated_data)}.items():
    method = exp_data['method']
    if method in methods and 'compute' in exp_data['summary_stats']:
        inference_times.setdefault(method, []).append(exp_data['summary_stats']['compute']['inference_time']['mean'])

# Create plot
fig, ax = plt.subplots(figsize=(10, 6))
method_names = list(inference_times.keys())
avg_times = [np.mean(inference_times[method]) for method in method_names]

bars = ax.bar(method_names, avg_times, color=['#4ECDC4', '#FF6B6B', '#45B7D1'][:len(method_names)])
ax.set_ylabel('Average Inference Time (seconds)')
ax.set_title('Inference Time Comparison by Method')
ax.grid(axis='y', alpha=0.3)

# Add value labels
for bar in bars:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2, height + 0.1,
            f'{{height:.3f}}s', ha='center', va='bottom')

plt.tight_layout()
plt.savefig(analysis_dir / 'inference_time_comparison.png', dpi=300)
plt.show()
"""
        return viz_code

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Infrastructure Analysis for Multi-Agent Systems')
    parser.add_argument('--metrics_dir', type=str, default='metrics',
                       help='Directory containing metrics JSON files')
    parser.add_argument('--output_dir', type=str, default='analysis_results',
                       help='Directory to save analysis results')
    parser.add_argument('--methods', type=str, nargs='+',
                       help='Specific methods to analyze (e.g., latent_mas text_mas baseline)')
    
    args = parser.parse_args()
    
    print(f"ðŸ” Starting infrastructure analysis...")
    print(f"ðŸ“ Metrics directory: {args.metrics_dir}")
    print(f"ðŸ“Š Output directory: {args.output_dir}")
    
    # åˆ›å»ºåˆ†æžå™¨
    analyzer = InfrastructureAnalyzer(
        metrics_dir=args.metrics_dir,
        output_dir=args.output_dir
    )
    
    # èŽ·å–è¦åˆ†æžçš„æ–¹æ³•
    methods_to_analyze = args.methods if args.methods else None
    
    # ç”Ÿæˆå®Œæ•´åˆ†æž
    analyzer.compare_methods(methods=methods_to_analyze)
    
    # ç”Ÿæˆå¯è§†åŒ–ä»£ç ç¤ºä¾‹
    viz_code = analyzer.generate_visualization_code()
    code_path = analyzer.output_dir / 'visualization_examples.py'
    with open(code_path, 'w') as f:
        f.write(viz_code)
    print(f"âœ… Visualization examples saved to: {code_path}")
    
    print(f"\nðŸŽ‰ Analysis completed successfully!")
    print(f"ðŸ“ˆ Find all results in: {analyzer.output_dir}")

if __name__ == "__main__":
    main()